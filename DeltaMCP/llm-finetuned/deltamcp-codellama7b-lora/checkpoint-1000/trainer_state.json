{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.202866593164278,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022050716648291068,
      "grad_norm": 0.279296875,
      "learning_rate": 9.854014598540146e-06,
      "loss": 0.499,
      "step": 10
    },
    {
      "epoch": 0.044101433296582136,
      "grad_norm": 0.291015625,
      "learning_rate": 2.0802919708029195e-05,
      "loss": 0.4698,
      "step": 20
    },
    {
      "epoch": 0.06615214994487321,
      "grad_norm": 0.318359375,
      "learning_rate": 3.175182481751824e-05,
      "loss": 0.3886,
      "step": 30
    },
    {
      "epoch": 0.08820286659316427,
      "grad_norm": 0.326171875,
      "learning_rate": 4.270072992700729e-05,
      "loss": 0.2426,
      "step": 40
    },
    {
      "epoch": 0.11025358324145534,
      "grad_norm": 0.267578125,
      "learning_rate": 5.3649635036496344e-05,
      "loss": 0.1141,
      "step": 50
    },
    {
      "epoch": 0.13230429988974643,
      "grad_norm": 0.1416015625,
      "learning_rate": 6.459854014598539e-05,
      "loss": 0.0709,
      "step": 60
    },
    {
      "epoch": 0.1543550165380375,
      "grad_norm": 0.1513671875,
      "learning_rate": 7.554744525547446e-05,
      "loss": 0.0539,
      "step": 70
    },
    {
      "epoch": 0.17640573318632854,
      "grad_norm": 0.138671875,
      "learning_rate": 8.649635036496349e-05,
      "loss": 0.0429,
      "step": 80
    },
    {
      "epoch": 0.19845644983461963,
      "grad_norm": 0.1337890625,
      "learning_rate": 9.744525547445255e-05,
      "loss": 0.0403,
      "step": 90
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 0.1201171875,
      "learning_rate": 0.0001083941605839416,
      "loss": 0.038,
      "step": 100
    },
    {
      "epoch": 0.24255788313120177,
      "grad_norm": 0.1328125,
      "learning_rate": 0.00011934306569343065,
      "loss": 0.0405,
      "step": 110
    },
    {
      "epoch": 0.26460859977949286,
      "grad_norm": 0.140625,
      "learning_rate": 0.0001302919708029197,
      "loss": 0.0314,
      "step": 120
    },
    {
      "epoch": 0.2866593164277839,
      "grad_norm": 0.1279296875,
      "learning_rate": 0.00014124087591240874,
      "loss": 0.029,
      "step": 130
    },
    {
      "epoch": 0.308710033076075,
      "grad_norm": 0.10107421875,
      "learning_rate": 0.00014999901345278497,
      "loss": 0.0233,
      "step": 140
    },
    {
      "epoch": 0.33076074972436603,
      "grad_norm": 0.09716796875,
      "learning_rate": 0.0001499644870253537,
      "loss": 0.0242,
      "step": 150
    },
    {
      "epoch": 0.3528114663726571,
      "grad_norm": 0.14453125,
      "learning_rate": 0.000149880659188113,
      "loss": 0.0293,
      "step": 160
    },
    {
      "epoch": 0.3748621830209482,
      "grad_norm": 0.08447265625,
      "learning_rate": 0.00014974758507157492,
      "loss": 0.0247,
      "step": 170
    },
    {
      "epoch": 0.39691289966923926,
      "grad_norm": 0.11474609375,
      "learning_rate": 0.00014956535219373383,
      "loss": 0.0221,
      "step": 180
    },
    {
      "epoch": 0.4189636163175303,
      "grad_norm": 0.09619140625,
      "learning_rate": 0.00014933408040250908,
      "loss": 0.0278,
      "step": 190
    },
    {
      "epoch": 0.4410143329658214,
      "grad_norm": 0.05517578125,
      "learning_rate": 0.00014905392179692523,
      "loss": 0.0222,
      "step": 200
    },
    {
      "epoch": 0.46306504961411243,
      "grad_norm": 0.1259765625,
      "learning_rate": 0.0001487250606270822,
      "loss": 0.0252,
      "step": 210
    },
    {
      "epoch": 0.48511576626240355,
      "grad_norm": 0.1162109375,
      "learning_rate": 0.00014834771317298072,
      "loss": 0.0199,
      "step": 220
    },
    {
      "epoch": 0.5071664829106945,
      "grad_norm": 0.10791015625,
      "learning_rate": 0.0001479221276022827,
      "loss": 0.0228,
      "step": 230
    },
    {
      "epoch": 0.5292171995589857,
      "grad_norm": 0.07666015625,
      "learning_rate": 0.0001474485838071006,
      "loss": 0.0237,
      "step": 240
    },
    {
      "epoch": 0.5512679162072768,
      "grad_norm": 0.057373046875,
      "learning_rate": 0.0001469273932199224,
      "loss": 0.019,
      "step": 250
    },
    {
      "epoch": 0.5733186328555678,
      "grad_norm": 0.0859375,
      "learning_rate": 0.00014635889860879406,
      "loss": 0.0215,
      "step": 260
    },
    {
      "epoch": 0.5953693495038589,
      "grad_norm": 0.0732421875,
      "learning_rate": 0.00014574347385189315,
      "loss": 0.0243,
      "step": 270
    },
    {
      "epoch": 0.61742006615215,
      "grad_norm": 0.08544921875,
      "learning_rate": 0.0001450815236916431,
      "loss": 0.0215,
      "step": 280
    },
    {
      "epoch": 0.639470782800441,
      "grad_norm": 0.08154296875,
      "learning_rate": 0.00014437348346852872,
      "loss": 0.0195,
      "step": 290
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 0.0986328125,
      "learning_rate": 0.0001436198188347886,
      "loss": 0.0241,
      "step": 300
    },
    {
      "epoch": 0.6835722160970231,
      "grad_norm": 0.0703125,
      "learning_rate": 0.0001428210254481727,
      "loss": 0.0189,
      "step": 310
    },
    {
      "epoch": 0.7056229327453142,
      "grad_norm": 0.0732421875,
      "learning_rate": 0.0001419776286459664,
      "loss": 0.0162,
      "step": 320
    },
    {
      "epoch": 0.7276736493936052,
      "grad_norm": 0.06982421875,
      "learning_rate": 0.00014109018309949503,
      "loss": 0.0195,
      "step": 330
    },
    {
      "epoch": 0.7497243660418964,
      "grad_norm": 0.054931640625,
      "learning_rate": 0.00014015927244933707,
      "loss": 0.0161,
      "step": 340
    },
    {
      "epoch": 0.7717750826901875,
      "grad_norm": 0.076171875,
      "learning_rate": 0.00013918550892148482,
      "loss": 0.0157,
      "step": 350
    },
    {
      "epoch": 0.7938257993384785,
      "grad_norm": 0.07080078125,
      "learning_rate": 0.00013816953292470585,
      "loss": 0.0189,
      "step": 360
    },
    {
      "epoch": 0.8158765159867696,
      "grad_norm": 0.09912109375,
      "learning_rate": 0.00013711201262936936,
      "loss": 0.0211,
      "step": 370
    },
    {
      "epoch": 0.8379272326350606,
      "grad_norm": 0.08544921875,
      "learning_rate": 0.00013601364352801496,
      "loss": 0.0194,
      "step": 380
    },
    {
      "epoch": 0.8599779492833517,
      "grad_norm": 0.059814453125,
      "learning_rate": 0.0001348751479779526,
      "loss": 0.0154,
      "step": 390
    },
    {
      "epoch": 0.8820286659316428,
      "grad_norm": 0.05224609375,
      "learning_rate": 0.00013369727472619443,
      "loss": 0.024,
      "step": 400
    },
    {
      "epoch": 0.9040793825799338,
      "grad_norm": 0.07861328125,
      "learning_rate": 0.0001324807984170313,
      "loss": 0.0179,
      "step": 410
    },
    {
      "epoch": 0.9261300992282249,
      "grad_norm": 0.0654296875,
      "learning_rate": 0.00013122651908257734,
      "loss": 0.0174,
      "step": 420
    },
    {
      "epoch": 0.948180815876516,
      "grad_norm": 0.07763671875,
      "learning_rate": 0.00012993526161661815,
      "loss": 0.0167,
      "step": 430
    },
    {
      "epoch": 0.9702315325248071,
      "grad_norm": 0.056640625,
      "learning_rate": 0.000128607875232108,
      "loss": 0.0162,
      "step": 440
    },
    {
      "epoch": 0.9922822491730982,
      "grad_norm": 0.054443359375,
      "learning_rate": 0.0001272452329026737,
      "loss": 0.0199,
      "step": 450
    },
    {
      "epoch": 1.0132304299889747,
      "grad_norm": 0.0458984375,
      "learning_rate": 0.00012584823078849155,
      "loss": 0.0169,
      "step": 460
    },
    {
      "epoch": 1.0352811466372658,
      "grad_norm": 0.05029296875,
      "learning_rate": 0.00012441778764691545,
      "loss": 0.0142,
      "step": 470
    },
    {
      "epoch": 1.0573318632855568,
      "grad_norm": 0.061279296875,
      "learning_rate": 0.0001229548442282437,
      "loss": 0.0145,
      "step": 480
    },
    {
      "epoch": 1.079382579933848,
      "grad_norm": 0.061279296875,
      "learning_rate": 0.00012146036265702185,
      "loss": 0.0138,
      "step": 490
    },
    {
      "epoch": 1.101433296582139,
      "grad_norm": 0.052734375,
      "learning_rate": 0.00011993532579928849,
      "loss": 0.0123,
      "step": 500
    },
    {
      "epoch": 1.12348401323043,
      "grad_norm": 0.08154296875,
      "learning_rate": 0.00011838073661618,
      "loss": 0.0141,
      "step": 510
    },
    {
      "epoch": 1.145534729878721,
      "grad_norm": 0.07080078125,
      "learning_rate": 0.00011679761750431968,
      "loss": 0.0132,
      "step": 520
    },
    {
      "epoch": 1.1675854465270121,
      "grad_norm": 0.056884765625,
      "learning_rate": 0.00011518700962342473,
      "loss": 0.0123,
      "step": 530
    },
    {
      "epoch": 1.1896361631753032,
      "grad_norm": 0.056640625,
      "learning_rate": 0.00011354997221157349,
      "loss": 0.0145,
      "step": 540
    },
    {
      "epoch": 1.2116868798235942,
      "grad_norm": 0.0537109375,
      "learning_rate": 0.00011188758188858309,
      "loss": 0.0135,
      "step": 550
    },
    {
      "epoch": 1.2337375964718853,
      "grad_norm": 0.05615234375,
      "learning_rate": 0.00011020093194795595,
      "loss": 0.0128,
      "step": 560
    },
    {
      "epoch": 1.2557883131201764,
      "grad_norm": 0.068359375,
      "learning_rate": 0.00010849113163786049,
      "loss": 0.0135,
      "step": 570
    },
    {
      "epoch": 1.2778390297684674,
      "grad_norm": 0.03759765625,
      "learning_rate": 0.000106759305431619,
      "loss": 0.0125,
      "step": 580
    },
    {
      "epoch": 1.2998897464167585,
      "grad_norm": 0.07666015625,
      "learning_rate": 0.00010500659228818259,
      "loss": 0.0132,
      "step": 590
    },
    {
      "epoch": 1.3219404630650495,
      "grad_norm": 0.05322265625,
      "learning_rate": 0.00010323414490307938,
      "loss": 0.0143,
      "step": 600
    },
    {
      "epoch": 1.3439911797133406,
      "grad_norm": 0.0634765625,
      "learning_rate": 0.00010144312895032874,
      "loss": 0.0129,
      "step": 610
    },
    {
      "epoch": 1.3660418963616316,
      "grad_norm": 0.0546875,
      "learning_rate": 9.963472231581992e-05,
      "loss": 0.0154,
      "step": 620
    },
    {
      "epoch": 1.3880926130099227,
      "grad_norm": 0.0458984375,
      "learning_rate": 9.781011432265945e-05,
      "loss": 0.0161,
      "step": 630
    },
    {
      "epoch": 1.4101433296582138,
      "grad_norm": 0.04443359375,
      "learning_rate": 9.597050494899675e-05,
      "loss": 0.0125,
      "step": 640
    },
    {
      "epoch": 1.432194046306505,
      "grad_norm": 0.08837890625,
      "learning_rate": 9.41171040388422e-05,
      "loss": 0.0145,
      "step": 650
    },
    {
      "epoch": 1.454244762954796,
      "grad_norm": 0.041748046875,
      "learning_rate": 9.225113050639692e-05,
      "loss": 0.0125,
      "step": 660
    },
    {
      "epoch": 1.4762954796030872,
      "grad_norm": 0.0732421875,
      "learning_rate": 9.037381153441729e-05,
      "loss": 0.0116,
      "step": 670
    },
    {
      "epoch": 1.4983461962513782,
      "grad_norm": 0.064453125,
      "learning_rate": 8.848638176714149e-05,
      "loss": 0.0122,
      "step": 680
    },
    {
      "epoch": 1.5203969128996693,
      "grad_norm": 0.05029296875,
      "learning_rate": 8.659008249830926e-05,
      "loss": 0.014,
      "step": 690
    },
    {
      "epoch": 1.5424476295479603,
      "grad_norm": 0.05126953125,
      "learning_rate": 8.46861608548081e-05,
      "loss": 0.0123,
      "step": 700
    },
    {
      "epoch": 1.5644983461962514,
      "grad_norm": 0.042236328125,
      "learning_rate": 8.27758689764833e-05,
      "loss": 0.0124,
      "step": 710
    },
    {
      "epoch": 1.5865490628445424,
      "grad_norm": 0.046142578125,
      "learning_rate": 8.086046319265142e-05,
      "loss": 0.0125,
      "step": 720
    },
    {
      "epoch": 1.6085997794928335,
      "grad_norm": 0.140625,
      "learning_rate": 7.894120319585823e-05,
      "loss": 0.0128,
      "step": 730
    },
    {
      "epoch": 1.6306504961411246,
      "grad_norm": 0.05908203125,
      "learning_rate": 7.70193512134247e-05,
      "loss": 0.0136,
      "step": 740
    },
    {
      "epoch": 1.6527012127894156,
      "grad_norm": 0.050048828125,
      "learning_rate": 7.509617117732642e-05,
      "loss": 0.0132,
      "step": 750
    },
    {
      "epoch": 1.6747519294377067,
      "grad_norm": 0.057373046875,
      "learning_rate": 7.317292789295134e-05,
      "loss": 0.0113,
      "step": 760
    },
    {
      "epoch": 1.696802646085998,
      "grad_norm": 0.047607421875,
      "learning_rate": 7.125088620728353e-05,
      "loss": 0.0117,
      "step": 770
    },
    {
      "epoch": 1.718853362734289,
      "grad_norm": 0.060546875,
      "learning_rate": 6.933131017705942e-05,
      "loss": 0.0124,
      "step": 780
    },
    {
      "epoch": 1.74090407938258,
      "grad_norm": 0.04443359375,
      "learning_rate": 6.741546223744367e-05,
      "loss": 0.0133,
      "step": 790
    },
    {
      "epoch": 1.7629547960308711,
      "grad_norm": 0.053955078125,
      "learning_rate": 6.550460237177184e-05,
      "loss": 0.0127,
      "step": 800
    },
    {
      "epoch": 1.7850055126791622,
      "grad_norm": 0.052001953125,
      "learning_rate": 6.359998728290495e-05,
      "loss": 0.0107,
      "step": 810
    },
    {
      "epoch": 1.8070562293274532,
      "grad_norm": 0.056640625,
      "learning_rate": 6.170286956674217e-05,
      "loss": 0.0118,
      "step": 820
    },
    {
      "epoch": 1.8291069459757443,
      "grad_norm": 0.04638671875,
      "learning_rate": 5.9814496888433875e-05,
      "loss": 0.0124,
      "step": 830
    },
    {
      "epoch": 1.8511576626240354,
      "grad_norm": 0.06884765625,
      "learning_rate": 5.7936111161837956e-05,
      "loss": 0.0114,
      "step": 840
    },
    {
      "epoch": 1.8732083792723264,
      "grad_norm": 0.04345703125,
      "learning_rate": 5.606894773275831e-05,
      "loss": 0.0135,
      "step": 850
    },
    {
      "epoch": 1.8952590959206175,
      "grad_norm": 0.04345703125,
      "learning_rate": 5.421423456650295e-05,
      "loss": 0.0106,
      "step": 860
    },
    {
      "epoch": 1.9173098125689085,
      "grad_norm": 0.07421875,
      "learning_rate": 5.237319144029591e-05,
      "loss": 0.0136,
      "step": 870
    },
    {
      "epoch": 1.9393605292171996,
      "grad_norm": 0.07421875,
      "learning_rate": 5.0547029141074356e-05,
      "loss": 0.0139,
      "step": 880
    },
    {
      "epoch": 1.9614112458654906,
      "grad_norm": 0.05615234375,
      "learning_rate": 4.873694866919818e-05,
      "loss": 0.013,
      "step": 890
    },
    {
      "epoch": 1.9834619625137817,
      "grad_norm": 0.05224609375,
      "learning_rate": 4.69441404485957e-05,
      "loss": 0.0119,
      "step": 900
    },
    {
      "epoch": 2.0044101433296584,
      "grad_norm": 0.052734375,
      "learning_rate": 4.516978354386542e-05,
      "loss": 0.0112,
      "step": 910
    },
    {
      "epoch": 2.0264608599779494,
      "grad_norm": 0.043701171875,
      "learning_rate": 4.341504488484808e-05,
      "loss": 0.0093,
      "step": 920
    },
    {
      "epoch": 2.0485115766262405,
      "grad_norm": 0.044677734375,
      "learning_rate": 4.168107849917955e-05,
      "loss": 0.0085,
      "step": 930
    },
    {
      "epoch": 2.0705622932745316,
      "grad_norm": 0.045654296875,
      "learning_rate": 3.996902475332895e-05,
      "loss": 0.0085,
      "step": 940
    },
    {
      "epoch": 2.0926130099228226,
      "grad_norm": 0.037109375,
      "learning_rate": 3.828000960262109e-05,
      "loss": 0.008,
      "step": 950
    },
    {
      "epoch": 2.1146637265711137,
      "grad_norm": 0.054931640625,
      "learning_rate": 3.6615143850736764e-05,
      "loss": 0.0101,
      "step": 960
    },
    {
      "epoch": 2.1367144432194047,
      "grad_norm": 0.03369140625,
      "learning_rate": 3.497552241917782e-05,
      "loss": 0.0092,
      "step": 970
    },
    {
      "epoch": 2.158765159867696,
      "grad_norm": 0.0576171875,
      "learning_rate": 3.33622236271769e-05,
      "loss": 0.0099,
      "step": 980
    },
    {
      "epoch": 2.180815876515987,
      "grad_norm": 0.046630859375,
      "learning_rate": 3.1776308482526424e-05,
      "loss": 0.0097,
      "step": 990
    },
    {
      "epoch": 2.202866593164278,
      "grad_norm": 0.06591796875,
      "learning_rate": 3.0218819983792462e-05,
      "loss": 0.0085,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1362,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4468166777031885e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
