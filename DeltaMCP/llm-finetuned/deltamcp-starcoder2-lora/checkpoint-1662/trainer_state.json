{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1662,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01807501129688206,
      "grad_norm": 0.5163688063621521,
      "learning_rate": 1.0778443113772455e-05,
      "loss": 1.1282,
      "step": 10
    },
    {
      "epoch": 0.03615002259376412,
      "grad_norm": 0.744081437587738,
      "learning_rate": 2.275449101796407e-05,
      "loss": 1.0897,
      "step": 20
    },
    {
      "epoch": 0.05422503389064618,
      "grad_norm": 1.3504685163497925,
      "learning_rate": 3.473053892215569e-05,
      "loss": 0.8978,
      "step": 30
    },
    {
      "epoch": 0.07230004518752824,
      "grad_norm": 1.4089515209197998,
      "learning_rate": 4.670658682634731e-05,
      "loss": 0.6338,
      "step": 40
    },
    {
      "epoch": 0.0903750564844103,
      "grad_norm": 1.6099028587341309,
      "learning_rate": 5.868263473053892e-05,
      "loss": 0.4099,
      "step": 50
    },
    {
      "epoch": 0.10845006778129236,
      "grad_norm": 1.0727548599243164,
      "learning_rate": 7.065868263473055e-05,
      "loss": 0.2363,
      "step": 60
    },
    {
      "epoch": 0.12652507907817442,
      "grad_norm": 1.1767003536224365,
      "learning_rate": 8.1437125748503e-05,
      "loss": 0.1792,
      "step": 70
    },
    {
      "epoch": 0.14460009037505647,
      "grad_norm": 0.8995717167854309,
      "learning_rate": 9.341317365269462e-05,
      "loss": 0.1601,
      "step": 80
    },
    {
      "epoch": 0.16267510167193855,
      "grad_norm": 0.7891271710395813,
      "learning_rate": 0.00010538922155688624,
      "loss": 0.1011,
      "step": 90
    },
    {
      "epoch": 0.1807501129688206,
      "grad_norm": 0.6539335250854492,
      "learning_rate": 0.00011736526946107784,
      "loss": 0.1182,
      "step": 100
    },
    {
      "epoch": 0.19882512426570267,
      "grad_norm": 0.8094465136528015,
      "learning_rate": 0.00012934131736526947,
      "loss": 0.0998,
      "step": 110
    },
    {
      "epoch": 0.21690013556258472,
      "grad_norm": 0.4545556306838989,
      "learning_rate": 0.0001413173652694611,
      "loss": 0.0898,
      "step": 120
    },
    {
      "epoch": 0.2349751468594668,
      "grad_norm": 0.5847088098526001,
      "learning_rate": 0.00015329341317365272,
      "loss": 0.0841,
      "step": 130
    },
    {
      "epoch": 0.25305015815634885,
      "grad_norm": 0.5277462601661682,
      "learning_rate": 0.00016526946107784431,
      "loss": 0.0911,
      "step": 140
    },
    {
      "epoch": 0.2711251694532309,
      "grad_norm": 0.7115408778190613,
      "learning_rate": 0.00017724550898203594,
      "loss": 0.0813,
      "step": 150
    },
    {
      "epoch": 0.28920018075011295,
      "grad_norm": 0.3515866994857788,
      "learning_rate": 0.00018922155688622756,
      "loss": 0.0721,
      "step": 160
    },
    {
      "epoch": 0.30727519204699505,
      "grad_norm": 0.3269958794116974,
      "learning_rate": 0.00019986622073578595,
      "loss": 0.0796,
      "step": 170
    },
    {
      "epoch": 0.3253502033438771,
      "grad_norm": 0.39510494470596313,
      "learning_rate": 0.0001985284280936455,
      "loss": 0.0688,
      "step": 180
    },
    {
      "epoch": 0.34342521464075915,
      "grad_norm": 0.37228724360466003,
      "learning_rate": 0.00019719063545150503,
      "loss": 0.0782,
      "step": 190
    },
    {
      "epoch": 0.3615002259376412,
      "grad_norm": 0.2607514560222626,
      "learning_rate": 0.00019585284280936456,
      "loss": 0.0829,
      "step": 200
    },
    {
      "epoch": 0.37957523723452324,
      "grad_norm": 0.3260040581226349,
      "learning_rate": 0.00019451505016722408,
      "loss": 0.0693,
      "step": 210
    },
    {
      "epoch": 0.39765024853140535,
      "grad_norm": 0.3323862850666046,
      "learning_rate": 0.0001931772575250836,
      "loss": 0.0628,
      "step": 220
    },
    {
      "epoch": 0.4157252598282874,
      "grad_norm": 0.32413920760154724,
      "learning_rate": 0.00019183946488294317,
      "loss": 0.0693,
      "step": 230
    },
    {
      "epoch": 0.43380027112516945,
      "grad_norm": 0.26953423023223877,
      "learning_rate": 0.0001905016722408027,
      "loss": 0.0812,
      "step": 240
    },
    {
      "epoch": 0.4518752824220515,
      "grad_norm": 0.3466387093067169,
      "learning_rate": 0.00018916387959866222,
      "loss": 0.0654,
      "step": 250
    },
    {
      "epoch": 0.4699502937189336,
      "grad_norm": 0.2958184778690338,
      "learning_rate": 0.00018782608695652175,
      "loss": 0.062,
      "step": 260
    },
    {
      "epoch": 0.48802530501581565,
      "grad_norm": 0.2266235500574112,
      "learning_rate": 0.00018648829431438128,
      "loss": 0.0526,
      "step": 270
    },
    {
      "epoch": 0.5061003163126977,
      "grad_norm": 0.29494449496269226,
      "learning_rate": 0.0001851505016722408,
      "loss": 0.0547,
      "step": 280
    },
    {
      "epoch": 0.5241753276095797,
      "grad_norm": 0.2915286719799042,
      "learning_rate": 0.00018381270903010036,
      "loss": 0.0724,
      "step": 290
    },
    {
      "epoch": 0.5422503389064618,
      "grad_norm": 0.24879910051822662,
      "learning_rate": 0.0001824749163879599,
      "loss": 0.0671,
      "step": 300
    },
    {
      "epoch": 0.5603253502033438,
      "grad_norm": 0.299391508102417,
      "learning_rate": 0.00018113712374581942,
      "loss": 0.0643,
      "step": 310
    },
    {
      "epoch": 0.5784003615002259,
      "grad_norm": 0.22925716638565063,
      "learning_rate": 0.00017979933110367894,
      "loss": 0.051,
      "step": 320
    },
    {
      "epoch": 0.596475372797108,
      "grad_norm": 0.25304079055786133,
      "learning_rate": 0.00017846153846153847,
      "loss": 0.0454,
      "step": 330
    },
    {
      "epoch": 0.6145503840939901,
      "grad_norm": 0.25401103496551514,
      "learning_rate": 0.00017712374581939803,
      "loss": 0.0513,
      "step": 340
    },
    {
      "epoch": 0.6326253953908721,
      "grad_norm": 0.3890686631202698,
      "learning_rate": 0.00017578595317725753,
      "loss": 0.0674,
      "step": 350
    },
    {
      "epoch": 0.6507004066877542,
      "grad_norm": 0.27611976861953735,
      "learning_rate": 0.00017444816053511705,
      "loss": 0.0564,
      "step": 360
    },
    {
      "epoch": 0.6687754179846362,
      "grad_norm": 0.2445988804101944,
      "learning_rate": 0.00017311036789297658,
      "loss": 0.0507,
      "step": 370
    },
    {
      "epoch": 0.6868504292815183,
      "grad_norm": 0.21433356404304504,
      "learning_rate": 0.0001717725752508361,
      "loss": 0.0591,
      "step": 380
    },
    {
      "epoch": 0.7049254405784003,
      "grad_norm": 0.2192673236131668,
      "learning_rate": 0.00017043478260869566,
      "loss": 0.0473,
      "step": 390
    },
    {
      "epoch": 0.7230004518752824,
      "grad_norm": 0.22382667660713196,
      "learning_rate": 0.0001690969899665552,
      "loss": 0.0488,
      "step": 400
    },
    {
      "epoch": 0.7410754631721644,
      "grad_norm": 0.35290542244911194,
      "learning_rate": 0.00016775919732441472,
      "loss": 0.0459,
      "step": 410
    },
    {
      "epoch": 0.7591504744690465,
      "grad_norm": 0.25347626209259033,
      "learning_rate": 0.00016642140468227425,
      "loss": 0.0505,
      "step": 420
    },
    {
      "epoch": 0.7772254857659286,
      "grad_norm": 0.14967238903045654,
      "learning_rate": 0.00016508361204013378,
      "loss": 0.0442,
      "step": 430
    },
    {
      "epoch": 0.7953004970628107,
      "grad_norm": 0.2672538161277771,
      "learning_rate": 0.0001637458193979933,
      "loss": 0.0396,
      "step": 440
    },
    {
      "epoch": 0.8133755083596927,
      "grad_norm": 0.2993448078632355,
      "learning_rate": 0.00016240802675585286,
      "loss": 0.0535,
      "step": 450
    },
    {
      "epoch": 0.8314505196565748,
      "grad_norm": 0.25864169001579285,
      "learning_rate": 0.00016107023411371239,
      "loss": 0.053,
      "step": 460
    },
    {
      "epoch": 0.8495255309534568,
      "grad_norm": 0.21633191406726837,
      "learning_rate": 0.0001597324414715719,
      "loss": 0.0457,
      "step": 470
    },
    {
      "epoch": 0.8676005422503389,
      "grad_norm": 0.28219255805015564,
      "learning_rate": 0.00015839464882943144,
      "loss": 0.0457,
      "step": 480
    },
    {
      "epoch": 0.8856755535472209,
      "grad_norm": 0.23629209399223328,
      "learning_rate": 0.00015705685618729097,
      "loss": 0.0421,
      "step": 490
    },
    {
      "epoch": 0.903750564844103,
      "grad_norm": 0.24029593169689178,
      "learning_rate": 0.00015571906354515052,
      "loss": 0.0465,
      "step": 500
    },
    {
      "epoch": 0.921825576140985,
      "grad_norm": 0.26504603028297424,
      "learning_rate": 0.00015438127090301005,
      "loss": 0.0415,
      "step": 510
    },
    {
      "epoch": 0.9399005874378672,
      "grad_norm": 0.28704530000686646,
      "learning_rate": 0.00015304347826086958,
      "loss": 0.0433,
      "step": 520
    },
    {
      "epoch": 0.9579755987347492,
      "grad_norm": 0.26172691583633423,
      "learning_rate": 0.0001517056856187291,
      "loss": 0.0398,
      "step": 530
    },
    {
      "epoch": 0.9760506100316313,
      "grad_norm": 0.21553336083889008,
      "learning_rate": 0.00015036789297658863,
      "loss": 0.0404,
      "step": 540
    },
    {
      "epoch": 0.9941256213285133,
      "grad_norm": 0.1876511573791504,
      "learning_rate": 0.00014903010033444816,
      "loss": 0.0406,
      "step": 550
    },
    {
      "epoch": 1.0108450067781292,
      "grad_norm": 0.4339836835861206,
      "learning_rate": 0.00014769230769230772,
      "loss": 0.0421,
      "step": 560
    },
    {
      "epoch": 1.0289200180750113,
      "grad_norm": 0.24711357057094574,
      "learning_rate": 0.00014635451505016724,
      "loss": 0.0383,
      "step": 570
    },
    {
      "epoch": 1.0469950293718933,
      "grad_norm": 0.14006443321704865,
      "learning_rate": 0.00014501672240802677,
      "loss": 0.0362,
      "step": 580
    },
    {
      "epoch": 1.0650700406687754,
      "grad_norm": 0.18251009285449982,
      "learning_rate": 0.0001436789297658863,
      "loss": 0.0432,
      "step": 590
    },
    {
      "epoch": 1.0831450519656576,
      "grad_norm": 0.16938160359859467,
      "learning_rate": 0.00014234113712374583,
      "loss": 0.0396,
      "step": 600
    },
    {
      "epoch": 1.1012200632625395,
      "grad_norm": 0.17454352974891663,
      "learning_rate": 0.00014100334448160536,
      "loss": 0.0395,
      "step": 610
    },
    {
      "epoch": 1.1192950745594217,
      "grad_norm": 0.24447418749332428,
      "learning_rate": 0.00013966555183946488,
      "loss": 0.0348,
      "step": 620
    },
    {
      "epoch": 1.1373700858563036,
      "grad_norm": 0.21877560019493103,
      "learning_rate": 0.0001383277591973244,
      "loss": 0.0361,
      "step": 630
    },
    {
      "epoch": 1.1554450971531858,
      "grad_norm": 0.20656220614910126,
      "learning_rate": 0.00013698996655518394,
      "loss": 0.0367,
      "step": 640
    },
    {
      "epoch": 1.1735201084500677,
      "grad_norm": 0.20227091014385223,
      "learning_rate": 0.00013565217391304347,
      "loss": 0.0329,
      "step": 650
    },
    {
      "epoch": 1.1915951197469499,
      "grad_norm": 0.18413950502872467,
      "learning_rate": 0.00013431438127090302,
      "loss": 0.0336,
      "step": 660
    },
    {
      "epoch": 1.2096701310438318,
      "grad_norm": 0.12358113378286362,
      "learning_rate": 0.00013297658862876255,
      "loss": 0.0363,
      "step": 670
    },
    {
      "epoch": 1.227745142340714,
      "grad_norm": 0.1955304890871048,
      "learning_rate": 0.00013163879598662208,
      "loss": 0.0397,
      "step": 680
    },
    {
      "epoch": 1.2458201536375961,
      "grad_norm": 0.29695427417755127,
      "learning_rate": 0.0001303010033444816,
      "loss": 0.0322,
      "step": 690
    },
    {
      "epoch": 1.263895164934478,
      "grad_norm": 0.2686358094215393,
      "learning_rate": 0.00012896321070234113,
      "loss": 0.0427,
      "step": 700
    },
    {
      "epoch": 1.2819701762313602,
      "grad_norm": 0.49558815360069275,
      "learning_rate": 0.0001276254180602007,
      "loss": 0.0383,
      "step": 710
    },
    {
      "epoch": 1.3000451875282422,
      "grad_norm": 0.39857253432273865,
      "learning_rate": 0.00012628762541806021,
      "loss": 0.044,
      "step": 720
    },
    {
      "epoch": 1.3181201988251243,
      "grad_norm": 0.19831588864326477,
      "learning_rate": 0.00012494983277591974,
      "loss": 0.039,
      "step": 730
    },
    {
      "epoch": 1.3361952101220063,
      "grad_norm": 0.12558838725090027,
      "learning_rate": 0.00012361204013377927,
      "loss": 0.0344,
      "step": 740
    },
    {
      "epoch": 1.3542702214188884,
      "grad_norm": 0.20158490538597107,
      "learning_rate": 0.0001222742474916388,
      "loss": 0.0421,
      "step": 750
    },
    {
      "epoch": 1.3723452327157704,
      "grad_norm": 0.19161923229694366,
      "learning_rate": 0.00012093645484949834,
      "loss": 0.0354,
      "step": 760
    },
    {
      "epoch": 1.3904202440126525,
      "grad_norm": 0.14884226024150848,
      "learning_rate": 0.00011959866220735787,
      "loss": 0.0354,
      "step": 770
    },
    {
      "epoch": 1.4084952553095347,
      "grad_norm": 0.23035746812820435,
      "learning_rate": 0.00011826086956521741,
      "loss": 0.0411,
      "step": 780
    },
    {
      "epoch": 1.4265702666064166,
      "grad_norm": 0.1432141810655594,
      "learning_rate": 0.00011692307692307694,
      "loss": 0.028,
      "step": 790
    },
    {
      "epoch": 1.4446452779032986,
      "grad_norm": 0.1377652883529663,
      "learning_rate": 0.00011558528428093646,
      "loss": 0.039,
      "step": 800
    },
    {
      "epoch": 1.4627202892001807,
      "grad_norm": 0.13283443450927734,
      "learning_rate": 0.000114247491638796,
      "loss": 0.033,
      "step": 810
    },
    {
      "epoch": 1.4807953004970629,
      "grad_norm": 0.18238608539104462,
      "learning_rate": 0.00011290969899665553,
      "loss": 0.0287,
      "step": 820
    },
    {
      "epoch": 1.4988703117939448,
      "grad_norm": 0.24930055439472198,
      "learning_rate": 0.00011157190635451506,
      "loss": 0.0362,
      "step": 830
    },
    {
      "epoch": 1.516945323090827,
      "grad_norm": 0.2911756932735443,
      "learning_rate": 0.0001102341137123746,
      "loss": 0.0373,
      "step": 840
    },
    {
      "epoch": 1.535020334387709,
      "grad_norm": 0.16212765872478485,
      "learning_rate": 0.0001088963210702341,
      "loss": 0.0328,
      "step": 850
    },
    {
      "epoch": 1.553095345684591,
      "grad_norm": 0.1792697012424469,
      "learning_rate": 0.00010755852842809364,
      "loss": 0.0313,
      "step": 860
    },
    {
      "epoch": 1.5711703569814732,
      "grad_norm": 0.17552952468395233,
      "learning_rate": 0.00010622073578595317,
      "loss": 0.0322,
      "step": 870
    },
    {
      "epoch": 1.5892453682783552,
      "grad_norm": 0.2700856029987335,
      "learning_rate": 0.00010488294314381271,
      "loss": 0.0281,
      "step": 880
    },
    {
      "epoch": 1.607320379575237,
      "grad_norm": 0.20934127271175385,
      "learning_rate": 0.00010354515050167224,
      "loss": 0.0344,
      "step": 890
    },
    {
      "epoch": 1.6253953908721193,
      "grad_norm": 0.20325464010238647,
      "learning_rate": 0.00010220735785953177,
      "loss": 0.0344,
      "step": 900
    },
    {
      "epoch": 1.6434704021690014,
      "grad_norm": 0.10764985531568527,
      "learning_rate": 0.00010086956521739131,
      "loss": 0.0326,
      "step": 910
    },
    {
      "epoch": 1.6615454134658836,
      "grad_norm": 0.16839002072811127,
      "learning_rate": 9.953177257525084e-05,
      "loss": 0.0316,
      "step": 920
    },
    {
      "epoch": 1.6796204247627655,
      "grad_norm": 0.14916127920150757,
      "learning_rate": 9.819397993311036e-05,
      "loss": 0.0317,
      "step": 930
    },
    {
      "epoch": 1.6976954360596475,
      "grad_norm": 0.15504811704158783,
      "learning_rate": 9.68561872909699e-05,
      "loss": 0.0338,
      "step": 940
    },
    {
      "epoch": 1.7157704473565296,
      "grad_norm": 0.2922663986682892,
      "learning_rate": 9.551839464882943e-05,
      "loss": 0.0303,
      "step": 950
    },
    {
      "epoch": 1.7338454586534118,
      "grad_norm": 0.189725860953331,
      "learning_rate": 9.418060200668896e-05,
      "loss": 0.0304,
      "step": 960
    },
    {
      "epoch": 1.7519204699502937,
      "grad_norm": 0.17477434873580933,
      "learning_rate": 9.28428093645485e-05,
      "loss": 0.0306,
      "step": 970
    },
    {
      "epoch": 1.7699954812471757,
      "grad_norm": 0.236154705286026,
      "learning_rate": 9.150501672240803e-05,
      "loss": 0.0309,
      "step": 980
    },
    {
      "epoch": 1.7880704925440578,
      "grad_norm": 0.2581876218318939,
      "learning_rate": 9.016722408026757e-05,
      "loss": 0.0315,
      "step": 990
    },
    {
      "epoch": 1.80614550384094,
      "grad_norm": 0.2484593689441681,
      "learning_rate": 8.88294314381271e-05,
      "loss": 0.0323,
      "step": 1000
    },
    {
      "epoch": 1.824220515137822,
      "grad_norm": 0.15521474182605743,
      "learning_rate": 8.749163879598663e-05,
      "loss": 0.0294,
      "step": 1010
    },
    {
      "epoch": 1.842295526434704,
      "grad_norm": 0.24547192454338074,
      "learning_rate": 8.615384615384617e-05,
      "loss": 0.0315,
      "step": 1020
    },
    {
      "epoch": 1.860370537731586,
      "grad_norm": 0.16481159627437592,
      "learning_rate": 8.481605351170568e-05,
      "loss": 0.0354,
      "step": 1030
    },
    {
      "epoch": 1.8784455490284682,
      "grad_norm": 0.23882761597633362,
      "learning_rate": 8.347826086956521e-05,
      "loss": 0.0318,
      "step": 1040
    },
    {
      "epoch": 1.8965205603253503,
      "grad_norm": 0.1968134641647339,
      "learning_rate": 8.214046822742475e-05,
      "loss": 0.0345,
      "step": 1050
    },
    {
      "epoch": 1.9145955716222323,
      "grad_norm": 0.13757051527500153,
      "learning_rate": 8.080267558528428e-05,
      "loss": 0.027,
      "step": 1060
    },
    {
      "epoch": 1.9326705829191142,
      "grad_norm": 0.14465858042240143,
      "learning_rate": 7.946488294314382e-05,
      "loss": 0.0307,
      "step": 1070
    },
    {
      "epoch": 1.9507455942159964,
      "grad_norm": 0.1320316344499588,
      "learning_rate": 7.812709030100335e-05,
      "loss": 0.0299,
      "step": 1080
    },
    {
      "epoch": 1.9688206055128785,
      "grad_norm": 0.17551015317440033,
      "learning_rate": 7.678929765886288e-05,
      "loss": 0.0299,
      "step": 1090
    },
    {
      "epoch": 1.9868956168097605,
      "grad_norm": 0.12224894016981125,
      "learning_rate": 7.545150501672242e-05,
      "loss": 0.0283,
      "step": 1100
    },
    {
      "epoch": 2.0036150022593766,
      "grad_norm": 0.1300671100616455,
      "learning_rate": 7.411371237458194e-05,
      "loss": 0.0254,
      "step": 1110
    },
    {
      "epoch": 2.0216900135562583,
      "grad_norm": 0.1174493134021759,
      "learning_rate": 7.277591973244147e-05,
      "loss": 0.0258,
      "step": 1120
    },
    {
      "epoch": 2.0397650248531405,
      "grad_norm": 0.2130127102136612,
      "learning_rate": 7.143812709030101e-05,
      "loss": 0.027,
      "step": 1130
    },
    {
      "epoch": 2.0578400361500226,
      "grad_norm": 0.19133152067661285,
      "learning_rate": 7.010033444816054e-05,
      "loss": 0.0301,
      "step": 1140
    },
    {
      "epoch": 2.075915047446905,
      "grad_norm": 0.26809045672416687,
      "learning_rate": 6.876254180602007e-05,
      "loss": 0.0308,
      "step": 1150
    },
    {
      "epoch": 2.0939900587437865,
      "grad_norm": 0.10216851532459259,
      "learning_rate": 6.74247491638796e-05,
      "loss": 0.0242,
      "step": 1160
    },
    {
      "epoch": 2.1120650700406687,
      "grad_norm": 0.17444968223571777,
      "learning_rate": 6.608695652173912e-05,
      "loss": 0.0243,
      "step": 1170
    },
    {
      "epoch": 2.130140081337551,
      "grad_norm": 0.14444781839847565,
      "learning_rate": 6.474916387959867e-05,
      "loss": 0.028,
      "step": 1180
    },
    {
      "epoch": 2.148215092634433,
      "grad_norm": 0.14247171580791473,
      "learning_rate": 6.34113712374582e-05,
      "loss": 0.0225,
      "step": 1190
    },
    {
      "epoch": 2.166290103931315,
      "grad_norm": 0.20779603719711304,
      "learning_rate": 6.207357859531772e-05,
      "loss": 0.0258,
      "step": 1200
    },
    {
      "epoch": 2.184365115228197,
      "grad_norm": 0.21001483500003815,
      "learning_rate": 6.073578595317726e-05,
      "loss": 0.0286,
      "step": 1210
    },
    {
      "epoch": 2.202440126525079,
      "grad_norm": 0.21454840898513794,
      "learning_rate": 5.939799331103679e-05,
      "loss": 0.0275,
      "step": 1220
    },
    {
      "epoch": 2.220515137821961,
      "grad_norm": 0.2785288691520691,
      "learning_rate": 5.8060200668896325e-05,
      "loss": 0.0245,
      "step": 1230
    },
    {
      "epoch": 2.2385901491188434,
      "grad_norm": 0.20248103141784668,
      "learning_rate": 5.672240802675586e-05,
      "loss": 0.0239,
      "step": 1240
    },
    {
      "epoch": 2.256665160415725,
      "grad_norm": 0.13362835347652435,
      "learning_rate": 5.538461538461539e-05,
      "loss": 0.0213,
      "step": 1250
    },
    {
      "epoch": 2.2747401717126072,
      "grad_norm": 0.29888543486595154,
      "learning_rate": 5.404682274247492e-05,
      "loss": 0.0252,
      "step": 1260
    },
    {
      "epoch": 2.2928151830094894,
      "grad_norm": 0.15922360122203827,
      "learning_rate": 5.2709030100334456e-05,
      "loss": 0.0268,
      "step": 1270
    },
    {
      "epoch": 2.3108901943063715,
      "grad_norm": 0.1254931092262268,
      "learning_rate": 5.137123745819398e-05,
      "loss": 0.0266,
      "step": 1280
    },
    {
      "epoch": 2.3289652056032537,
      "grad_norm": 0.15422925353050232,
      "learning_rate": 5.003344481605351e-05,
      "loss": 0.0251,
      "step": 1290
    },
    {
      "epoch": 2.3470402169001354,
      "grad_norm": 0.166244238615036,
      "learning_rate": 4.8695652173913046e-05,
      "loss": 0.0223,
      "step": 1300
    },
    {
      "epoch": 2.3651152281970176,
      "grad_norm": 0.22479625046253204,
      "learning_rate": 4.7357859531772574e-05,
      "loss": 0.0289,
      "step": 1310
    },
    {
      "epoch": 2.3831902394938997,
      "grad_norm": 0.1536116898059845,
      "learning_rate": 4.602006688963211e-05,
      "loss": 0.0253,
      "step": 1320
    },
    {
      "epoch": 2.401265250790782,
      "grad_norm": 0.22918780148029327,
      "learning_rate": 4.468227424749164e-05,
      "loss": 0.028,
      "step": 1330
    },
    {
      "epoch": 2.4193402620876636,
      "grad_norm": 0.15660512447357178,
      "learning_rate": 4.334448160535117e-05,
      "loss": 0.0273,
      "step": 1340
    },
    {
      "epoch": 2.4374152733845458,
      "grad_norm": 0.14922726154327393,
      "learning_rate": 4.2006688963210705e-05,
      "loss": 0.0211,
      "step": 1350
    },
    {
      "epoch": 2.455490284681428,
      "grad_norm": 0.17288105189800262,
      "learning_rate": 4.066889632107024e-05,
      "loss": 0.0212,
      "step": 1360
    },
    {
      "epoch": 2.47356529597831,
      "grad_norm": 0.18172229826450348,
      "learning_rate": 3.933110367892977e-05,
      "loss": 0.0277,
      "step": 1370
    },
    {
      "epoch": 2.4916403072751923,
      "grad_norm": 0.191461980342865,
      "learning_rate": 3.7993311036789295e-05,
      "loss": 0.0253,
      "step": 1380
    },
    {
      "epoch": 2.509715318572074,
      "grad_norm": 0.20085978507995605,
      "learning_rate": 3.665551839464883e-05,
      "loss": 0.0312,
      "step": 1390
    },
    {
      "epoch": 2.527790329868956,
      "grad_norm": 0.16792787611484528,
      "learning_rate": 3.5317725752508364e-05,
      "loss": 0.0223,
      "step": 1400
    },
    {
      "epoch": 2.5458653411658383,
      "grad_norm": 0.13045606017112732,
      "learning_rate": 3.39799331103679e-05,
      "loss": 0.0236,
      "step": 1410
    },
    {
      "epoch": 2.5639403524627205,
      "grad_norm": 0.16820695996284485,
      "learning_rate": 3.2642140468227426e-05,
      "loss": 0.026,
      "step": 1420
    },
    {
      "epoch": 2.582015363759602,
      "grad_norm": 0.1509183943271637,
      "learning_rate": 3.130434782608696e-05,
      "loss": 0.0252,
      "step": 1430
    },
    {
      "epoch": 2.6000903750564843,
      "grad_norm": 0.28437739610671997,
      "learning_rate": 2.9966555183946488e-05,
      "loss": 0.0276,
      "step": 1440
    },
    {
      "epoch": 2.6181653863533665,
      "grad_norm": 0.1607702672481537,
      "learning_rate": 2.862876254180602e-05,
      "loss": 0.0278,
      "step": 1450
    },
    {
      "epoch": 2.6362403976502486,
      "grad_norm": 0.1769397109746933,
      "learning_rate": 2.7290969899665554e-05,
      "loss": 0.0226,
      "step": 1460
    },
    {
      "epoch": 2.654315408947131,
      "grad_norm": 0.1570456624031067,
      "learning_rate": 2.5953177257525085e-05,
      "loss": 0.0212,
      "step": 1470
    },
    {
      "epoch": 2.6723904202440125,
      "grad_norm": 0.16071653366088867,
      "learning_rate": 2.461538461538462e-05,
      "loss": 0.03,
      "step": 1480
    },
    {
      "epoch": 2.6904654315408947,
      "grad_norm": 0.143787682056427,
      "learning_rate": 2.3277591973244147e-05,
      "loss": 0.0233,
      "step": 1490
    },
    {
      "epoch": 2.708540442837777,
      "grad_norm": 0.17679722607135773,
      "learning_rate": 2.1939799331103682e-05,
      "loss": 0.0212,
      "step": 1500
    },
    {
      "epoch": 2.726615454134659,
      "grad_norm": 0.13439232110977173,
      "learning_rate": 2.0602006688963213e-05,
      "loss": 0.0256,
      "step": 1510
    },
    {
      "epoch": 2.7446904654315407,
      "grad_norm": 0.17583774030208588,
      "learning_rate": 1.9264214046822744e-05,
      "loss": 0.0252,
      "step": 1520
    },
    {
      "epoch": 2.762765476728423,
      "grad_norm": 0.3035104274749756,
      "learning_rate": 1.7926421404682275e-05,
      "loss": 0.0212,
      "step": 1530
    },
    {
      "epoch": 2.780840488025305,
      "grad_norm": 0.3151404559612274,
      "learning_rate": 1.658862876254181e-05,
      "loss": 0.0285,
      "step": 1540
    },
    {
      "epoch": 2.798915499322187,
      "grad_norm": 0.12144631147384644,
      "learning_rate": 1.5250836120401337e-05,
      "loss": 0.0226,
      "step": 1550
    },
    {
      "epoch": 2.8169905106190694,
      "grad_norm": 0.19460292160511017,
      "learning_rate": 1.391304347826087e-05,
      "loss": 0.0228,
      "step": 1560
    },
    {
      "epoch": 2.835065521915951,
      "grad_norm": 0.25545623898506165,
      "learning_rate": 1.2575250836120403e-05,
      "loss": 0.0218,
      "step": 1570
    },
    {
      "epoch": 2.8531405332128332,
      "grad_norm": 0.23537854850292206,
      "learning_rate": 1.1237458193979934e-05,
      "loss": 0.0284,
      "step": 1580
    },
    {
      "epoch": 2.8712155445097154,
      "grad_norm": 0.29543381929397583,
      "learning_rate": 9.899665551839465e-06,
      "loss": 0.0281,
      "step": 1590
    },
    {
      "epoch": 2.889290555806597,
      "grad_norm": 0.18499568104743958,
      "learning_rate": 8.561872909698996e-06,
      "loss": 0.0228,
      "step": 1600
    },
    {
      "epoch": 2.9073655671034793,
      "grad_norm": 0.19672012329101562,
      "learning_rate": 7.224080267558529e-06,
      "loss": 0.0263,
      "step": 1610
    },
    {
      "epoch": 2.9254405784003614,
      "grad_norm": 0.14022845029830933,
      "learning_rate": 5.88628762541806e-06,
      "loss": 0.024,
      "step": 1620
    },
    {
      "epoch": 2.9435155896972436,
      "grad_norm": 0.21469110250473022,
      "learning_rate": 4.548494983277592e-06,
      "loss": 0.0265,
      "step": 1630
    },
    {
      "epoch": 2.9615906009941257,
      "grad_norm": 0.160552516579628,
      "learning_rate": 3.2107023411371236e-06,
      "loss": 0.0249,
      "step": 1640
    },
    {
      "epoch": 2.979665612291008,
      "grad_norm": 0.3331361711025238,
      "learning_rate": 1.8729096989966555e-06,
      "loss": 0.0235,
      "step": 1650
    },
    {
      "epoch": 2.9977406235878896,
      "grad_norm": 0.2028621882200241,
      "learning_rate": 5.351170568561873e-07,
      "loss": 0.0239,
      "step": 1660
    }
  ],
  "logging_steps": 10,
  "max_steps": 1662,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8416641757452698e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
