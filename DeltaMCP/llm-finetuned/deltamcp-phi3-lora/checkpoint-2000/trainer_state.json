{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.941522618609783,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01471129091577786,
      "grad_norm": 0.49235132336616516,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.7834,
      "step": 10
    },
    {
      "epoch": 0.02942258183155572,
      "grad_norm": 0.28582537174224854,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.7664,
      "step": 20
    },
    {
      "epoch": 0.04413387274733358,
      "grad_norm": 0.2796139121055603,
      "learning_rate": 2.7450980392156865e-05,
      "loss": 0.7446,
      "step": 30
    },
    {
      "epoch": 0.05884516366311144,
      "grad_norm": 0.2555375099182129,
      "learning_rate": 3.725490196078432e-05,
      "loss": 0.7194,
      "step": 40
    },
    {
      "epoch": 0.07355645457888929,
      "grad_norm": 0.2956582009792328,
      "learning_rate": 4.705882352941177e-05,
      "loss": 0.6116,
      "step": 50
    },
    {
      "epoch": 0.08826774549466716,
      "grad_norm": 0.34479230642318726,
      "learning_rate": 5.6862745098039215e-05,
      "loss": 0.5315,
      "step": 60
    },
    {
      "epoch": 0.10297903641044502,
      "grad_norm": 0.3856005370616913,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.3618,
      "step": 70
    },
    {
      "epoch": 0.11769032732622288,
      "grad_norm": 0.37029534578323364,
      "learning_rate": 7.647058823529411e-05,
      "loss": 0.2364,
      "step": 80
    },
    {
      "epoch": 0.13240161824200072,
      "grad_norm": 0.28218597173690796,
      "learning_rate": 8.627450980392158e-05,
      "loss": 0.1625,
      "step": 90
    },
    {
      "epoch": 0.14711290915777858,
      "grad_norm": 0.2550661265850067,
      "learning_rate": 9.607843137254903e-05,
      "loss": 0.135,
      "step": 100
    },
    {
      "epoch": 0.16182420007355647,
      "grad_norm": 0.32298019528388977,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.1095,
      "step": 110
    },
    {
      "epoch": 0.17653549098933433,
      "grad_norm": 0.20533029735088348,
      "learning_rate": 0.00011568627450980394,
      "loss": 0.1194,
      "step": 120
    },
    {
      "epoch": 0.19124678190511218,
      "grad_norm": 0.24890202283859253,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.1018,
      "step": 130
    },
    {
      "epoch": 0.20595807282089004,
      "grad_norm": 0.26174914836883545,
      "learning_rate": 0.00013529411764705884,
      "loss": 0.1026,
      "step": 140
    },
    {
      "epoch": 0.2206693637366679,
      "grad_norm": 0.29020392894744873,
      "learning_rate": 0.00014509803921568628,
      "loss": 0.0917,
      "step": 150
    },
    {
      "epoch": 0.23538065465244576,
      "grad_norm": 0.22020253539085388,
      "learning_rate": 0.00015490196078431375,
      "loss": 0.0856,
      "step": 160
    },
    {
      "epoch": 0.2500919455682236,
      "grad_norm": 0.25838184356689453,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0901,
      "step": 170
    },
    {
      "epoch": 0.26480323648400145,
      "grad_norm": 0.20779487490653992,
      "learning_rate": 0.00017450980392156863,
      "loss": 0.0859,
      "step": 180
    },
    {
      "epoch": 0.27951452739977933,
      "grad_norm": 0.23565129935741425,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0758,
      "step": 190
    },
    {
      "epoch": 0.29422581831555716,
      "grad_norm": 0.25659799575805664,
      "learning_rate": 0.00019411764705882354,
      "loss": 0.0721,
      "step": 200
    },
    {
      "epoch": 0.30893710923133505,
      "grad_norm": 0.3037740886211395,
      "learning_rate": 0.00019956427015250546,
      "loss": 0.0708,
      "step": 210
    },
    {
      "epoch": 0.32364840014711294,
      "grad_norm": 0.15457847714424133,
      "learning_rate": 0.00019847494553376906,
      "loss": 0.0892,
      "step": 220
    },
    {
      "epoch": 0.33835969106289077,
      "grad_norm": 0.2034483551979065,
      "learning_rate": 0.0001973856209150327,
      "loss": 0.0825,
      "step": 230
    },
    {
      "epoch": 0.35307098197866865,
      "grad_norm": 0.2241179198026657,
      "learning_rate": 0.0001962962962962963,
      "loss": 0.088,
      "step": 240
    },
    {
      "epoch": 0.3677822728944465,
      "grad_norm": 0.22059008479118347,
      "learning_rate": 0.00019520697167755993,
      "loss": 0.0724,
      "step": 250
    },
    {
      "epoch": 0.38249356381022437,
      "grad_norm": 0.20503513514995575,
      "learning_rate": 0.00019411764705882354,
      "loss": 0.0579,
      "step": 260
    },
    {
      "epoch": 0.3972048547260022,
      "grad_norm": 0.22157837450504303,
      "learning_rate": 0.00019302832244008715,
      "loss": 0.0688,
      "step": 270
    },
    {
      "epoch": 0.4119161456417801,
      "grad_norm": 0.185410276055336,
      "learning_rate": 0.00019193899782135075,
      "loss": 0.0738,
      "step": 280
    },
    {
      "epoch": 0.4266274365575579,
      "grad_norm": 0.2781202495098114,
      "learning_rate": 0.0001908496732026144,
      "loss": 0.0788,
      "step": 290
    },
    {
      "epoch": 0.4413387274733358,
      "grad_norm": 0.3885234296321869,
      "learning_rate": 0.00018976034858387802,
      "loss": 0.067,
      "step": 300
    },
    {
      "epoch": 0.45605001838911363,
      "grad_norm": 0.21487107872962952,
      "learning_rate": 0.00018867102396514162,
      "loss": 0.0586,
      "step": 310
    },
    {
      "epoch": 0.4707613093048915,
      "grad_norm": 0.2019694298505783,
      "learning_rate": 0.00018758169934640523,
      "loss": 0.0621,
      "step": 320
    },
    {
      "epoch": 0.48547260022066935,
      "grad_norm": 0.2007049322128296,
      "learning_rate": 0.00018649237472766886,
      "loss": 0.0629,
      "step": 330
    },
    {
      "epoch": 0.5001838911364472,
      "grad_norm": 0.1756361722946167,
      "learning_rate": 0.00018540305010893247,
      "loss": 0.0598,
      "step": 340
    },
    {
      "epoch": 0.5148951820522251,
      "grad_norm": 0.18956199288368225,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.057,
      "step": 350
    },
    {
      "epoch": 0.5296064729680029,
      "grad_norm": 0.2777213752269745,
      "learning_rate": 0.0001832244008714597,
      "loss": 0.0616,
      "step": 360
    },
    {
      "epoch": 0.5443177638837808,
      "grad_norm": 0.17143991589546204,
      "learning_rate": 0.00018213507625272334,
      "loss": 0.053,
      "step": 370
    },
    {
      "epoch": 0.5590290547995587,
      "grad_norm": 0.22188283503055573,
      "learning_rate": 0.00018104575163398694,
      "loss": 0.0505,
      "step": 380
    },
    {
      "epoch": 0.5737403457153365,
      "grad_norm": 0.14957019686698914,
      "learning_rate": 0.00017995642701525055,
      "loss": 0.043,
      "step": 390
    },
    {
      "epoch": 0.5884516366311143,
      "grad_norm": 0.24199780821800232,
      "learning_rate": 0.00017886710239651415,
      "loss": 0.0495,
      "step": 400
    },
    {
      "epoch": 0.6031629275468923,
      "grad_norm": 0.22830529510974884,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.0524,
      "step": 410
    },
    {
      "epoch": 0.6178742184626701,
      "grad_norm": 0.17870868742465973,
      "learning_rate": 0.00017668845315904142,
      "loss": 0.057,
      "step": 420
    },
    {
      "epoch": 0.6325855093784479,
      "grad_norm": 0.21756941080093384,
      "learning_rate": 0.00017559912854030502,
      "loss": 0.0554,
      "step": 430
    },
    {
      "epoch": 0.6472968002942259,
      "grad_norm": 0.16151933372020721,
      "learning_rate": 0.00017450980392156863,
      "loss": 0.058,
      "step": 440
    },
    {
      "epoch": 0.6620080912100037,
      "grad_norm": 0.2200014591217041,
      "learning_rate": 0.00017342047930283226,
      "loss": 0.0537,
      "step": 450
    },
    {
      "epoch": 0.6767193821257815,
      "grad_norm": 0.17940625548362732,
      "learning_rate": 0.00017233115468409587,
      "loss": 0.05,
      "step": 460
    },
    {
      "epoch": 0.6914306730415594,
      "grad_norm": 0.21751350164413452,
      "learning_rate": 0.00017124183006535947,
      "loss": 0.0523,
      "step": 470
    },
    {
      "epoch": 0.7061419639573373,
      "grad_norm": 0.1626172959804535,
      "learning_rate": 0.0001701525054466231,
      "loss": 0.0554,
      "step": 480
    },
    {
      "epoch": 0.7208532548731151,
      "grad_norm": 0.16429731249809265,
      "learning_rate": 0.0001690631808278867,
      "loss": 0.0508,
      "step": 490
    },
    {
      "epoch": 0.735564545788893,
      "grad_norm": 0.18434499204158783,
      "learning_rate": 0.00016797385620915035,
      "loss": 0.0489,
      "step": 500
    },
    {
      "epoch": 0.7502758367046708,
      "grad_norm": 0.16771766543388367,
      "learning_rate": 0.00016688453159041395,
      "loss": 0.0455,
      "step": 510
    },
    {
      "epoch": 0.7649871276204487,
      "grad_norm": 0.17351511120796204,
      "learning_rate": 0.00016579520697167756,
      "loss": 0.0474,
      "step": 520
    },
    {
      "epoch": 0.7796984185362266,
      "grad_norm": 0.18245482444763184,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0424,
      "step": 530
    },
    {
      "epoch": 0.7944097094520044,
      "grad_norm": 0.19964417815208435,
      "learning_rate": 0.00016361655773420482,
      "loss": 0.0461,
      "step": 540
    },
    {
      "epoch": 0.8091210003677822,
      "grad_norm": 0.19078101217746735,
      "learning_rate": 0.00016252723311546843,
      "loss": 0.0468,
      "step": 550
    },
    {
      "epoch": 0.8238322912835602,
      "grad_norm": 0.19000756740570068,
      "learning_rate": 0.00016143790849673203,
      "loss": 0.0419,
      "step": 560
    },
    {
      "epoch": 0.838543582199338,
      "grad_norm": 0.19122076034545898,
      "learning_rate": 0.00016034858387799564,
      "loss": 0.0427,
      "step": 570
    },
    {
      "epoch": 0.8532548731151158,
      "grad_norm": 0.1853904128074646,
      "learning_rate": 0.00015925925925925927,
      "loss": 0.0519,
      "step": 580
    },
    {
      "epoch": 0.8679661640308937,
      "grad_norm": 0.18576735258102417,
      "learning_rate": 0.00015816993464052288,
      "loss": 0.0386,
      "step": 590
    },
    {
      "epoch": 0.8826774549466716,
      "grad_norm": 0.2145865559577942,
      "learning_rate": 0.00015708061002178648,
      "loss": 0.051,
      "step": 600
    },
    {
      "epoch": 0.8973887458624494,
      "grad_norm": 0.18595534563064575,
      "learning_rate": 0.00015599128540305012,
      "loss": 0.0517,
      "step": 610
    },
    {
      "epoch": 0.9121000367782273,
      "grad_norm": 0.17672935128211975,
      "learning_rate": 0.00015490196078431375,
      "loss": 0.0432,
      "step": 620
    },
    {
      "epoch": 0.9268113276940051,
      "grad_norm": 0.17645449936389923,
      "learning_rate": 0.00015381263616557735,
      "loss": 0.0426,
      "step": 630
    },
    {
      "epoch": 0.941522618609783,
      "grad_norm": 0.14495818316936493,
      "learning_rate": 0.00015272331154684096,
      "loss": 0.0367,
      "step": 640
    },
    {
      "epoch": 0.9562339095255609,
      "grad_norm": 0.2685849368572235,
      "learning_rate": 0.00015163398692810456,
      "loss": 0.0399,
      "step": 650
    },
    {
      "epoch": 0.9709452004413387,
      "grad_norm": 0.18942825496196747,
      "learning_rate": 0.0001505446623093682,
      "loss": 0.039,
      "step": 660
    },
    {
      "epoch": 0.9856564913571166,
      "grad_norm": 0.14314526319503784,
      "learning_rate": 0.00014945533769063183,
      "loss": 0.0525,
      "step": 670
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.19815176725387573,
      "learning_rate": 0.00014836601307189544,
      "loss": 0.0388,
      "step": 680
    },
    {
      "epoch": 1.0147112909157778,
      "grad_norm": 0.18885046243667603,
      "learning_rate": 0.00014727668845315904,
      "loss": 0.0379,
      "step": 690
    },
    {
      "epoch": 1.0294225818315557,
      "grad_norm": 0.15636008977890015,
      "learning_rate": 0.00014618736383442267,
      "loss": 0.0373,
      "step": 700
    },
    {
      "epoch": 1.0441338727473335,
      "grad_norm": 0.16841429471969604,
      "learning_rate": 0.00014509803921568628,
      "loss": 0.036,
      "step": 710
    },
    {
      "epoch": 1.0588451636631115,
      "grad_norm": 0.15806877613067627,
      "learning_rate": 0.00014400871459694989,
      "loss": 0.0412,
      "step": 720
    },
    {
      "epoch": 1.0735564545788894,
      "grad_norm": 0.18941831588745117,
      "learning_rate": 0.00014291938997821352,
      "loss": 0.0415,
      "step": 730
    },
    {
      "epoch": 1.0882677454946672,
      "grad_norm": 0.1376066505908966,
      "learning_rate": 0.00014183006535947715,
      "loss": 0.0401,
      "step": 740
    },
    {
      "epoch": 1.102979036410445,
      "grad_norm": 0.15747228264808655,
      "learning_rate": 0.00014074074074074076,
      "loss": 0.042,
      "step": 750
    },
    {
      "epoch": 1.1176903273262229,
      "grad_norm": 0.21707557141780853,
      "learning_rate": 0.00013965141612200436,
      "loss": 0.0377,
      "step": 760
    },
    {
      "epoch": 1.1324016182420007,
      "grad_norm": 0.21296575665473938,
      "learning_rate": 0.00013856209150326797,
      "loss": 0.0325,
      "step": 770
    },
    {
      "epoch": 1.1471129091577785,
      "grad_norm": 0.18161383271217346,
      "learning_rate": 0.0001374727668845316,
      "loss": 0.0327,
      "step": 780
    },
    {
      "epoch": 1.1618242000735566,
      "grad_norm": 0.15729111433029175,
      "learning_rate": 0.0001363834422657952,
      "loss": 0.0333,
      "step": 790
    },
    {
      "epoch": 1.1765354909893344,
      "grad_norm": 0.16854166984558105,
      "learning_rate": 0.00013529411764705884,
      "loss": 0.027,
      "step": 800
    },
    {
      "epoch": 1.1912467819051122,
      "grad_norm": 0.19032502174377441,
      "learning_rate": 0.00013420479302832244,
      "loss": 0.0426,
      "step": 810
    },
    {
      "epoch": 1.20595807282089,
      "grad_norm": 0.1433054804801941,
      "learning_rate": 0.00013311546840958608,
      "loss": 0.0308,
      "step": 820
    },
    {
      "epoch": 1.220669363736668,
      "grad_norm": 0.1610950380563736,
      "learning_rate": 0.00013202614379084968,
      "loss": 0.0403,
      "step": 830
    },
    {
      "epoch": 1.2353806546524457,
      "grad_norm": 0.18568462133407593,
      "learning_rate": 0.0001309368191721133,
      "loss": 0.0308,
      "step": 840
    },
    {
      "epoch": 1.2500919455682236,
      "grad_norm": 0.1988651156425476,
      "learning_rate": 0.0001298474945533769,
      "loss": 0.0352,
      "step": 850
    },
    {
      "epoch": 1.2648032364840014,
      "grad_norm": 0.1347537338733673,
      "learning_rate": 0.00012875816993464053,
      "loss": 0.0358,
      "step": 860
    },
    {
      "epoch": 1.2795145273997792,
      "grad_norm": 0.16937753558158875,
      "learning_rate": 0.00012766884531590416,
      "loss": 0.0286,
      "step": 870
    },
    {
      "epoch": 1.294225818315557,
      "grad_norm": 0.17361639440059662,
      "learning_rate": 0.00012657952069716776,
      "loss": 0.0381,
      "step": 880
    },
    {
      "epoch": 1.308937109231335,
      "grad_norm": 0.17991195619106293,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.0425,
      "step": 890
    },
    {
      "epoch": 1.323648400147113,
      "grad_norm": 0.14924269914627075,
      "learning_rate": 0.000124400871459695,
      "loss": 0.0362,
      "step": 900
    },
    {
      "epoch": 1.3383596910628908,
      "grad_norm": 0.14892113208770752,
      "learning_rate": 0.0001233115468409586,
      "loss": 0.0307,
      "step": 910
    },
    {
      "epoch": 1.3530709819786686,
      "grad_norm": 0.18786728382110596,
      "learning_rate": 0.00012222222222222224,
      "loss": 0.034,
      "step": 920
    },
    {
      "epoch": 1.3677822728944464,
      "grad_norm": 0.2575955390930176,
      "learning_rate": 0.00012113289760348585,
      "loss": 0.0266,
      "step": 930
    },
    {
      "epoch": 1.3824935638102245,
      "grad_norm": 0.21907635033130646,
      "learning_rate": 0.00012004357298474947,
      "loss": 0.0329,
      "step": 940
    },
    {
      "epoch": 1.3972048547260023,
      "grad_norm": 0.17842014133930206,
      "learning_rate": 0.00011895424836601307,
      "loss": 0.0353,
      "step": 950
    },
    {
      "epoch": 1.4119161456417801,
      "grad_norm": 0.13168953359127045,
      "learning_rate": 0.00011786492374727669,
      "loss": 0.0299,
      "step": 960
    },
    {
      "epoch": 1.426627436557558,
      "grad_norm": 0.15490972995758057,
      "learning_rate": 0.0001167755991285403,
      "loss": 0.0306,
      "step": 970
    },
    {
      "epoch": 1.4413387274733358,
      "grad_norm": 0.18693625926971436,
      "learning_rate": 0.00011568627450980394,
      "loss": 0.0288,
      "step": 980
    },
    {
      "epoch": 1.4560500183891136,
      "grad_norm": 0.14723245799541473,
      "learning_rate": 0.00011459694989106755,
      "loss": 0.0303,
      "step": 990
    },
    {
      "epoch": 1.4707613093048915,
      "grad_norm": 0.264921098947525,
      "learning_rate": 0.00011350762527233117,
      "loss": 0.0368,
      "step": 1000
    },
    {
      "epoch": 1.4854726002206693,
      "grad_norm": 0.13597416877746582,
      "learning_rate": 0.00011241830065359477,
      "loss": 0.0321,
      "step": 1010
    },
    {
      "epoch": 1.5001838911364471,
      "grad_norm": 0.1980472207069397,
      "learning_rate": 0.00011132897603485839,
      "loss": 0.0287,
      "step": 1020
    },
    {
      "epoch": 1.514895182052225,
      "grad_norm": 0.2052367776632309,
      "learning_rate": 0.000110239651416122,
      "loss": 0.0348,
      "step": 1030
    },
    {
      "epoch": 1.5296064729680028,
      "grad_norm": 0.22645816206932068,
      "learning_rate": 0.00010915032679738562,
      "loss": 0.0282,
      "step": 1040
    },
    {
      "epoch": 1.5443177638837808,
      "grad_norm": 0.17073477804660797,
      "learning_rate": 0.00010806100217864925,
      "loss": 0.0299,
      "step": 1050
    },
    {
      "epoch": 1.5590290547995587,
      "grad_norm": 0.1356765627861023,
      "learning_rate": 0.00010697167755991287,
      "loss": 0.0259,
      "step": 1060
    },
    {
      "epoch": 1.5737403457153365,
      "grad_norm": 0.17722879350185394,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.023,
      "step": 1070
    },
    {
      "epoch": 1.5884516366311143,
      "grad_norm": 0.19107437133789062,
      "learning_rate": 0.0001047930283224401,
      "loss": 0.0287,
      "step": 1080
    },
    {
      "epoch": 1.6031629275468924,
      "grad_norm": 0.18741004168987274,
      "learning_rate": 0.0001037037037037037,
      "loss": 0.0313,
      "step": 1090
    },
    {
      "epoch": 1.6178742184626702,
      "grad_norm": 0.19276246428489685,
      "learning_rate": 0.00010261437908496732,
      "loss": 0.0311,
      "step": 1100
    },
    {
      "epoch": 1.632585509378448,
      "grad_norm": 0.1345285177230835,
      "learning_rate": 0.00010152505446623095,
      "loss": 0.0232,
      "step": 1110
    },
    {
      "epoch": 1.6472968002942259,
      "grad_norm": 0.17382749915122986,
      "learning_rate": 0.00010043572984749457,
      "loss": 0.0361,
      "step": 1120
    },
    {
      "epoch": 1.6620080912100037,
      "grad_norm": 0.22729086875915527,
      "learning_rate": 9.934640522875818e-05,
      "loss": 0.0425,
      "step": 1130
    },
    {
      "epoch": 1.6767193821257815,
      "grad_norm": 0.19516396522521973,
      "learning_rate": 9.82570806100218e-05,
      "loss": 0.0338,
      "step": 1140
    },
    {
      "epoch": 1.6914306730415594,
      "grad_norm": 0.17326582968235016,
      "learning_rate": 9.71677559912854e-05,
      "loss": 0.0262,
      "step": 1150
    },
    {
      "epoch": 1.7061419639573372,
      "grad_norm": 0.11490136384963989,
      "learning_rate": 9.607843137254903e-05,
      "loss": 0.0289,
      "step": 1160
    },
    {
      "epoch": 1.720853254873115,
      "grad_norm": 0.2551882863044739,
      "learning_rate": 9.498910675381264e-05,
      "loss": 0.0291,
      "step": 1170
    },
    {
      "epoch": 1.7355645457888929,
      "grad_norm": 0.12905295193195343,
      "learning_rate": 9.389978213507626e-05,
      "loss": 0.0223,
      "step": 1180
    },
    {
      "epoch": 1.7502758367046707,
      "grad_norm": 0.15373031795024872,
      "learning_rate": 9.281045751633988e-05,
      "loss": 0.0298,
      "step": 1190
    },
    {
      "epoch": 1.7649871276204487,
      "grad_norm": 0.1549571305513382,
      "learning_rate": 9.172113289760348e-05,
      "loss": 0.0256,
      "step": 1200
    },
    {
      "epoch": 1.7796984185362266,
      "grad_norm": 0.18407782912254333,
      "learning_rate": 9.06318082788671e-05,
      "loss": 0.0306,
      "step": 1210
    },
    {
      "epoch": 1.7944097094520044,
      "grad_norm": 0.18465735018253326,
      "learning_rate": 8.954248366013072e-05,
      "loss": 0.0325,
      "step": 1220
    },
    {
      "epoch": 1.8091210003677822,
      "grad_norm": 0.1364153027534485,
      "learning_rate": 8.845315904139434e-05,
      "loss": 0.0268,
      "step": 1230
    },
    {
      "epoch": 1.8238322912835603,
      "grad_norm": 0.1560070961713791,
      "learning_rate": 8.736383442265795e-05,
      "loss": 0.027,
      "step": 1240
    },
    {
      "epoch": 1.8385435821993381,
      "grad_norm": 0.16324549913406372,
      "learning_rate": 8.627450980392158e-05,
      "loss": 0.0272,
      "step": 1250
    },
    {
      "epoch": 1.853254873115116,
      "grad_norm": 0.14330056309700012,
      "learning_rate": 8.518518518518518e-05,
      "loss": 0.0217,
      "step": 1260
    },
    {
      "epoch": 1.8679661640308938,
      "grad_norm": 0.20612958073616028,
      "learning_rate": 8.40958605664488e-05,
      "loss": 0.0318,
      "step": 1270
    },
    {
      "epoch": 1.8826774549466716,
      "grad_norm": 0.17894795536994934,
      "learning_rate": 8.300653594771242e-05,
      "loss": 0.0269,
      "step": 1280
    },
    {
      "epoch": 1.8973887458624494,
      "grad_norm": 0.0999695286154747,
      "learning_rate": 8.191721132897604e-05,
      "loss": 0.0343,
      "step": 1290
    },
    {
      "epoch": 1.9121000367782273,
      "grad_norm": 0.14618954062461853,
      "learning_rate": 8.082788671023965e-05,
      "loss": 0.0271,
      "step": 1300
    },
    {
      "epoch": 1.926811327694005,
      "grad_norm": 0.1616719514131546,
      "learning_rate": 7.973856209150328e-05,
      "loss": 0.0264,
      "step": 1310
    },
    {
      "epoch": 1.941522618609783,
      "grad_norm": 0.18897974491119385,
      "learning_rate": 7.864923747276689e-05,
      "loss": 0.0308,
      "step": 1320
    },
    {
      "epoch": 1.9562339095255608,
      "grad_norm": 0.14592590928077698,
      "learning_rate": 7.75599128540305e-05,
      "loss": 0.0264,
      "step": 1330
    },
    {
      "epoch": 1.9709452004413386,
      "grad_norm": 0.22721640765666962,
      "learning_rate": 7.647058823529411e-05,
      "loss": 0.0245,
      "step": 1340
    },
    {
      "epoch": 1.9856564913571166,
      "grad_norm": 0.1533411741256714,
      "learning_rate": 7.538126361655774e-05,
      "loss": 0.0268,
      "step": 1350
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.1932050734758377,
      "learning_rate": 7.429193899782135e-05,
      "loss": 0.0297,
      "step": 1360
    },
    {
      "epoch": 2.014711290915778,
      "grad_norm": 0.13861101865768433,
      "learning_rate": 7.320261437908497e-05,
      "loss": 0.0242,
      "step": 1370
    },
    {
      "epoch": 2.0294225818315557,
      "grad_norm": 0.10160200297832489,
      "learning_rate": 7.211328976034859e-05,
      "loss": 0.0236,
      "step": 1380
    },
    {
      "epoch": 2.0441338727473335,
      "grad_norm": 0.1557440459728241,
      "learning_rate": 7.10239651416122e-05,
      "loss": 0.0215,
      "step": 1390
    },
    {
      "epoch": 2.0588451636631113,
      "grad_norm": 0.18126188218593597,
      "learning_rate": 6.993464052287581e-05,
      "loss": 0.0179,
      "step": 1400
    },
    {
      "epoch": 2.073556454578889,
      "grad_norm": 0.14227503538131714,
      "learning_rate": 6.884531590413945e-05,
      "loss": 0.024,
      "step": 1410
    },
    {
      "epoch": 2.088267745494667,
      "grad_norm": 0.1417674869298935,
      "learning_rate": 6.775599128540305e-05,
      "loss": 0.0234,
      "step": 1420
    },
    {
      "epoch": 2.102979036410445,
      "grad_norm": 0.1593625396490097,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0174,
      "step": 1430
    },
    {
      "epoch": 2.117690327326223,
      "grad_norm": 0.1477985978126526,
      "learning_rate": 6.557734204793029e-05,
      "loss": 0.0202,
      "step": 1440
    },
    {
      "epoch": 2.132401618242001,
      "grad_norm": 0.13635750114917755,
      "learning_rate": 6.448801742919391e-05,
      "loss": 0.0231,
      "step": 1450
    },
    {
      "epoch": 2.1471129091577787,
      "grad_norm": 0.24294599890708923,
      "learning_rate": 6.339869281045751e-05,
      "loss": 0.0275,
      "step": 1460
    },
    {
      "epoch": 2.1618242000735566,
      "grad_norm": 0.2164461612701416,
      "learning_rate": 6.230936819172115e-05,
      "loss": 0.0237,
      "step": 1470
    },
    {
      "epoch": 2.1765354909893344,
      "grad_norm": 0.1821105033159256,
      "learning_rate": 6.122004357298475e-05,
      "loss": 0.0273,
      "step": 1480
    },
    {
      "epoch": 2.1912467819051122,
      "grad_norm": 0.12600551545619965,
      "learning_rate": 6.0130718954248365e-05,
      "loss": 0.0272,
      "step": 1490
    },
    {
      "epoch": 2.20595807282089,
      "grad_norm": 0.12701921164989471,
      "learning_rate": 5.904139433551199e-05,
      "loss": 0.0198,
      "step": 1500
    },
    {
      "epoch": 2.220669363736668,
      "grad_norm": 0.12248656153678894,
      "learning_rate": 5.79520697167756e-05,
      "loss": 0.023,
      "step": 1510
    },
    {
      "epoch": 2.2353806546524457,
      "grad_norm": 0.15896941721439362,
      "learning_rate": 5.6862745098039215e-05,
      "loss": 0.0222,
      "step": 1520
    },
    {
      "epoch": 2.2500919455682236,
      "grad_norm": 0.1649327278137207,
      "learning_rate": 5.577342047930284e-05,
      "loss": 0.0244,
      "step": 1530
    },
    {
      "epoch": 2.2648032364840014,
      "grad_norm": 0.13929882645606995,
      "learning_rate": 5.4684095860566454e-05,
      "loss": 0.0169,
      "step": 1540
    },
    {
      "epoch": 2.2795145273997792,
      "grad_norm": 0.19955502450466156,
      "learning_rate": 5.3594771241830066e-05,
      "loss": 0.02,
      "step": 1550
    },
    {
      "epoch": 2.294225818315557,
      "grad_norm": 0.1854945421218872,
      "learning_rate": 5.250544662309368e-05,
      "loss": 0.0192,
      "step": 1560
    },
    {
      "epoch": 2.308937109231335,
      "grad_norm": 0.1102793738245964,
      "learning_rate": 5.1416122004357304e-05,
      "loss": 0.0237,
      "step": 1570
    },
    {
      "epoch": 2.323648400147113,
      "grad_norm": 0.1295914649963379,
      "learning_rate": 5.032679738562092e-05,
      "loss": 0.0198,
      "step": 1580
    },
    {
      "epoch": 2.338359691062891,
      "grad_norm": 0.11780361086130142,
      "learning_rate": 4.9237472766884536e-05,
      "loss": 0.0207,
      "step": 1590
    },
    {
      "epoch": 2.353070981978669,
      "grad_norm": 0.15776456892490387,
      "learning_rate": 4.814814814814815e-05,
      "loss": 0.0308,
      "step": 1600
    },
    {
      "epoch": 2.3677822728944466,
      "grad_norm": 0.17162904143333435,
      "learning_rate": 4.705882352941177e-05,
      "loss": 0.0168,
      "step": 1610
    },
    {
      "epoch": 2.3824935638102245,
      "grad_norm": 0.11902976036071777,
      "learning_rate": 4.5969498910675387e-05,
      "loss": 0.0241,
      "step": 1620
    },
    {
      "epoch": 2.3972048547260023,
      "grad_norm": 0.12735101580619812,
      "learning_rate": 4.4880174291939e-05,
      "loss": 0.0261,
      "step": 1630
    },
    {
      "epoch": 2.41191614564178,
      "grad_norm": 0.11141427606344223,
      "learning_rate": 4.379084967320262e-05,
      "loss": 0.0249,
      "step": 1640
    },
    {
      "epoch": 2.426627436557558,
      "grad_norm": 0.1385957896709442,
      "learning_rate": 4.270152505446624e-05,
      "loss": 0.0194,
      "step": 1650
    },
    {
      "epoch": 2.441338727473336,
      "grad_norm": 0.13722488284111023,
      "learning_rate": 4.161220043572985e-05,
      "loss": 0.0181,
      "step": 1660
    },
    {
      "epoch": 2.4560500183891136,
      "grad_norm": 0.13851913809776306,
      "learning_rate": 4.052287581699347e-05,
      "loss": 0.0205,
      "step": 1670
    },
    {
      "epoch": 2.4707613093048915,
      "grad_norm": 0.1303563117980957,
      "learning_rate": 3.943355119825709e-05,
      "loss": 0.0196,
      "step": 1680
    },
    {
      "epoch": 2.4854726002206693,
      "grad_norm": 0.14269351959228516,
      "learning_rate": 3.83442265795207e-05,
      "loss": 0.0291,
      "step": 1690
    },
    {
      "epoch": 2.500183891136447,
      "grad_norm": 0.14304569363594055,
      "learning_rate": 3.725490196078432e-05,
      "loss": 0.0233,
      "step": 1700
    },
    {
      "epoch": 2.514895182052225,
      "grad_norm": 0.1069575622677803,
      "learning_rate": 3.616557734204793e-05,
      "loss": 0.021,
      "step": 1710
    },
    {
      "epoch": 2.529606472968003,
      "grad_norm": 0.21280519664287567,
      "learning_rate": 3.507625272331155e-05,
      "loss": 0.0245,
      "step": 1720
    },
    {
      "epoch": 2.5443177638837806,
      "grad_norm": 0.1891230195760727,
      "learning_rate": 3.3986928104575163e-05,
      "loss": 0.0211,
      "step": 1730
    },
    {
      "epoch": 2.5590290547995584,
      "grad_norm": 0.19400310516357422,
      "learning_rate": 3.289760348583878e-05,
      "loss": 0.0192,
      "step": 1740
    },
    {
      "epoch": 2.5737403457153363,
      "grad_norm": 0.15799978375434875,
      "learning_rate": 3.1808278867102395e-05,
      "loss": 0.0241,
      "step": 1750
    },
    {
      "epoch": 2.588451636631114,
      "grad_norm": 0.1421670764684677,
      "learning_rate": 3.0718954248366014e-05,
      "loss": 0.0245,
      "step": 1760
    },
    {
      "epoch": 2.6031629275468924,
      "grad_norm": 0.14987440407276154,
      "learning_rate": 2.962962962962963e-05,
      "loss": 0.026,
      "step": 1770
    },
    {
      "epoch": 2.61787421846267,
      "grad_norm": 0.14586448669433594,
      "learning_rate": 2.854030501089325e-05,
      "loss": 0.0193,
      "step": 1780
    },
    {
      "epoch": 2.632585509378448,
      "grad_norm": 0.27801942825317383,
      "learning_rate": 2.7450980392156865e-05,
      "loss": 0.0202,
      "step": 1790
    },
    {
      "epoch": 2.647296800294226,
      "grad_norm": 0.19303132593631744,
      "learning_rate": 2.636165577342048e-05,
      "loss": 0.0228,
      "step": 1800
    },
    {
      "epoch": 2.6620080912100037,
      "grad_norm": 0.1532728224992752,
      "learning_rate": 2.5272331154684096e-05,
      "loss": 0.025,
      "step": 1810
    },
    {
      "epoch": 2.6767193821257815,
      "grad_norm": 0.22999602556228638,
      "learning_rate": 2.4183006535947712e-05,
      "loss": 0.026,
      "step": 1820
    },
    {
      "epoch": 2.6914306730415594,
      "grad_norm": 0.22648297250270844,
      "learning_rate": 2.3093681917211328e-05,
      "loss": 0.0249,
      "step": 1830
    },
    {
      "epoch": 2.706141963957337,
      "grad_norm": 0.15330782532691956,
      "learning_rate": 2.2004357298474944e-05,
      "loss": 0.0179,
      "step": 1840
    },
    {
      "epoch": 2.720853254873115,
      "grad_norm": 0.13168564438819885,
      "learning_rate": 2.0915032679738563e-05,
      "loss": 0.018,
      "step": 1850
    },
    {
      "epoch": 2.735564545788893,
      "grad_norm": 0.12360063195228577,
      "learning_rate": 1.982570806100218e-05,
      "loss": 0.0213,
      "step": 1860
    },
    {
      "epoch": 2.7502758367046707,
      "grad_norm": 0.17783820629119873,
      "learning_rate": 1.8736383442265794e-05,
      "loss": 0.0274,
      "step": 1870
    },
    {
      "epoch": 2.764987127620449,
      "grad_norm": 0.16212861239910126,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.0167,
      "step": 1880
    },
    {
      "epoch": 2.779698418536227,
      "grad_norm": 0.11599361896514893,
      "learning_rate": 1.655773420479303e-05,
      "loss": 0.0183,
      "step": 1890
    },
    {
      "epoch": 2.7944097094520046,
      "grad_norm": 0.18620282411575317,
      "learning_rate": 1.5468409586056645e-05,
      "loss": 0.0263,
      "step": 1900
    },
    {
      "epoch": 2.8091210003677825,
      "grad_norm": 0.16334067285060883,
      "learning_rate": 1.4379084967320261e-05,
      "loss": 0.0216,
      "step": 1910
    },
    {
      "epoch": 2.8238322912835603,
      "grad_norm": 0.15999537706375122,
      "learning_rate": 1.328976034858388e-05,
      "loss": 0.0153,
      "step": 1920
    },
    {
      "epoch": 2.838543582199338,
      "grad_norm": 0.14196589589118958,
      "learning_rate": 1.2200435729847496e-05,
      "loss": 0.0209,
      "step": 1930
    },
    {
      "epoch": 2.853254873115116,
      "grad_norm": 0.15032729506492615,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0208,
      "step": 1940
    },
    {
      "epoch": 2.8679661640308938,
      "grad_norm": 0.12766239047050476,
      "learning_rate": 1.0021786492374727e-05,
      "loss": 0.0201,
      "step": 1950
    },
    {
      "epoch": 2.8826774549466716,
      "grad_norm": 0.1522122025489807,
      "learning_rate": 8.932461873638345e-06,
      "loss": 0.0175,
      "step": 1960
    },
    {
      "epoch": 2.8973887458624494,
      "grad_norm": 0.13568353652954102,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0189,
      "step": 1970
    },
    {
      "epoch": 2.9121000367782273,
      "grad_norm": 0.189454585313797,
      "learning_rate": 6.753812636165578e-06,
      "loss": 0.0254,
      "step": 1980
    },
    {
      "epoch": 2.926811327694005,
      "grad_norm": 0.14097239077091217,
      "learning_rate": 5.664488017429194e-06,
      "loss": 0.0222,
      "step": 1990
    },
    {
      "epoch": 2.941522618609783,
      "grad_norm": 0.17766809463500977,
      "learning_rate": 4.5751633986928105e-06,
      "loss": 0.0188,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2040,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.831374450453381e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
