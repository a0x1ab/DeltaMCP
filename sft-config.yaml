model_name_or_path: bigcode/starcoder
use_peft: true
lora_r: 8
lora_alpha: 32
lora_dropout: 0.1
output_dir: DeltaMCP/llm-finetuned/sft-runs/DeltaMCP-StarCoder
learning_rate: 0.0002
num_train_epochs: 3
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 4
logging_steps: 10
evaluation_strategy: steps
eval_steps: 200
save_strategy: steps
save_steps: 200
save_total_limit: 2
fp16: true
report_to: none
dataset_text_field: text
max_length: 2048

dataset_train_split: train
dataset_test_split: test
datasets:
  - path: json
    data_files:
      train: DeltaMCP/llm-finetuned/training_data.jsonl
    split: train
test_split_size: 0.05
